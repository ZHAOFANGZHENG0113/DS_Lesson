{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14dcd53f",
   "metadata": {},
   "source": [
    "# Data Normalisation\n",
    "\n",
    "Normalisation is a common data pre-processing step, which involves changing the values of numeric columns in the data to a common scale, without distorting differences in the ranges of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9100219d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2198523",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "Load in a sample dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b36772c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"penguins_af.csv\", index_col=0)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91613e37",
   "metadata": {},
   "source": [
    "Inspect the numeric columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60adfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = [\"bill_length_mm\", \"bill_depth_mm\", \"flipper_length_mm\", \"body_mass_g\", \"year\"]\n",
    "df[numeric_columns].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec693b7b",
   "metadata": {},
   "source": [
    "From looking at the ranges for these numeric features, we can see that they are quite different:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e038894",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[numeric_columns].describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65948191",
   "metadata": {},
   "source": [
    "## Min-Max Normalisation\n",
    "\n",
    "One common preprocessing approach is **min-max normalisation**, which rescales the range of a feature's values to [0,1], based on its minimum and maximum values. \n",
    "\n",
    "We can use the *MinMaxScaler* implementation in scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fb0493",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# copy the original data\n",
    "X = df.copy()\n",
    "# apply the scaling process to the numeric columns\n",
    "scaler = MinMaxScaler()\n",
    "X[numeric_columns] = scaler.fit_transform(X[numeric_columns])\n",
    "# inspect the result\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11d6670",
   "metadata": {},
   "source": [
    "We can now see that the numeric features all have the same ranges - i.e. 0 to 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23703b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[numeric_columns].describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9b939b",
   "metadata": {},
   "source": [
    "We can also reverse the normalisation process, if we needed to get back our original data. This is done by applying an inverse transform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d2649a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the inverse transform\n",
    "Z = scaler.inverse_transform(X[numeric_columns])\n",
    "# turn the array back into a DataFrame\n",
    "pd.DataFrame(Z, index=X.index, columns=numeric_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec1ac49",
   "metadata": {},
   "source": [
    "## Z-Score Normalisation\n",
    "\n",
    "Another common approach is **z-score normalisation** (also sometimes called **standard scaling**). Here for all values for a feature, we subtract the feature mean and divide by the by the feature's standard deviation.\n",
    "\n",
    "We can apply this using the scikit-learn *StandardScaler* implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7f383b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# copy the original data\n",
    "X = df.copy()\n",
    "# apply the scaling process to the numeric columns\n",
    "scaler = StandardScaler()\n",
    "X[numeric_columns] = scaler.fit_transform(X[numeric_columns])\n",
    "# inspect the result\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1056bb1a",
   "metadata": {},
   "source": [
    "We can see that our features now have the same range:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526a8915",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[numeric_columns].describe().transpose()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
